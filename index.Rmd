---
title: "Practical Machine Learning Course Project"
author: "Steven Aurousseau"
date: "December 26, 2015"
output: html_document
---

## Summary
Analysis of 


## Background
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

In this project, the goal was to use data collected from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly, a total of 5 different ways:

1. exactly according to the specification (**Class A**),
2. throwing the elbows to the front (**Class B**),
3. lifting the dumbbell only halfway (**Class C**),
4. lowering the dumbbell only halfway (**Class D**)
5. throwing the hips to the front (**Class E**)

Read more at http://groupware.les.inf.puc-rio.br/har#ixzz3vXJtUIv8
*Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements*

# Load Data
```{r loadData}
library(caret, quietly = TRUE); library(ggplot2, quietly = TRUE)
setwd("~/Box Sync/Programming/Coursera - Data Science/8.0 Practical Machine Learning/course project")

# load Weight Lifting Exercise (WLE) dataset
if (! "trainingWLE.csv" %in% dir(getwd())) {
        trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
        download.file(trainURL, destfile = "trainingWLE.csv")
        rm(trainURL)
}
if (! "testingWLE.csv" %in% dir(getwd())) {
        testURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
        download.file(testURL, destfile = "testingWLE.csv")
        rm(testURL)
}
training <- read.csv("trainingWLE.csv")   # 20 160
testing <- read.csv("testingWLE.csv")  # 19622 160
```

# Cleaning Data 
## Count NA's in each column and clean-up
```{r removeNAs}
unique(colSums(!is.na(training))) # NA's are whole column or 406 rows
nas = sapply(training, function(x) {sum(is.na(x))})
# training <- training[, names(training) %in% names(nas[nas == 0])]
# testing <- testing[, names(testing) %in% names(nas[nas == 0])]  # repeat for testing data
training <- training[, names(training) %in% names(nas[nas < 407])] # 19622 93
testing <- testing[, names(testing) %in% names(nas[nas < 407])] # 20 92
rm(nas)
```
 
## Finally, remove near zero variance variables and decriptor columns 
```{r removeNZV}
# remove description and time cols
training <- training[,-c(1:7)]
testing <- testing[, -c(1:7)]
# remove near zero variance (NZV) variables
nzv <- nearZeroVar(training, saveMetrics=TRUE)
training <- training[, names(training) %in% rownames((nzv[nzv$nzv == 0, ]))]
testing <- testing[, names(testing) %in% rownames((nzv[nzv$nzv == 0, ]))]
rm(nzv)
```

# Split training data into train/validate with 60/40 split
```{r splitTrain}
set.seed(89)
inTrain <- createDataPartition(y=training$classe, p = 0.60, list=FALSE)
training <- training[inTrain, ]
validate <- training[-inTrain, ]
rm(inTrain)
```


# Classification Tree
Apply classification tree to dataset:
```{r classTree cache=TRUE}
mod.ct1 <- train(classe ~., method = 'rpart', data = training)
```

## Dendogram
```{r dendogram}
mod.ct1
mod.ct1$finalModel
# plot dendogram with rattle package
library(rattle, quietly = TRUE)
fancyRpartPlot(mod.ct1$finalModel)
```

Overall the classification tree model predicts `mod.ct1$result$Accuracy[1]` accuracy for the training dataset, which is only marginally above guessing (50/50 odds). Also, the classe D exercise is dropped completely from the final model so we are unable to predict that exercise set.

# Random Forest with Caret Package 
 
## Training the model 
A Random Forest training model was applied to the data with the caret package. Out of bag (OOB) error estimate method was used for the bootstrap datasets.
```{r randomForest cache=TRUE}
set.seed(89)
mod.rf5 <- train(classe ~., data = training,
                 method = 'rf',
                 trControl=trainControl(method='oob', seeds = c(89)),
                 proximity = TRUE)
mod.rf5
```
 
The accuracy of the final model is 
 
 
## Plot Model Convergence 
```{r rfConvergence}
# ```{r, echo = TRUE, fig.height=4.5, fig.width=4.5}
plot(mod.rf5)
```

# Cross Validate with the remaining 40% of training data
```{r rfValidate}
pred.rf5 <- predict(mod.rf5, validate)
# summary(pred.rf5)
confusionMatrix(pred.rf5, validate$classe)
```
  
- talk about accuracy
- talk about out of sample error

 
# Variable Importance 
```{r rfVarImp}
# ```{r, echo = TRUE, fig.height=4.5, fig.width=4.5}
varImp(mod.rf5)
plot(varImp(mod.rf5))
```
 
 
# Conclusion 




## Test Data 

# Calculation of Odds 
From the accuracy of the RF the odds getting 20 tests all correct
p^20 = 0.9992^20 = `0.9992^20`

# Test Prediction 
pred.rf.test <- predict(mod.rf5, testing)
summary(pred.rf.test)
# A B C D E
# 7 8 1 1 3
print(pred.rf.test)
#  [1] B A B A A E D B A A B C B A E E A B B B
#  Levels: A B C D E
 
  
# Generate Data for Submission






