---
title: "Practical Machine Learning Course Project"
author: "Steven Aurousseau"
date: "December 27, 2015"
output: html_document
---

## Background
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 
 
In this project, the goal was to use data collected from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly, a total of 5 different ways:
 
1. exactly according to the specification (**Class A**),
2. throwing the elbows to the front (**Class B**),
3. lifting the dumbbell only halfway (**Class C**),
4. lowering the dumbbell only halfway (**Class D**)
5. throwing the hips to the front (**Class E**)
 
Read more at http://groupware.les.inf.puc-rio.br/har#ixzz3vXJtUIv8
*Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements*
 
## Load Data
```{r loadData}
library(caret, quietly = TRUE); library(ggplot2, quietly = TRUE)
setwd("~/Box Sync/Programming/Coursera - Data Science/8.0 Practical Machine Learning/course project")
 
# load Weight Lifting Exercise (WLE) dataset
if (! "trainingWLE.csv" %in% dir(getwd())) {
        trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
        download.file(trainURL, destfile = "trainingWLE.csv")
        rm(trainURL)
}
if (! "testingWLE.csv" %in% dir(getwd())) {
        testURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
        download.file(testURL, destfile = "testingWLE.csv")
        rm(testURL)
}
training <- read.csv("trainingWLE.csv")   # 20 160
testing <- read.csv("testingWLE.csv")  # 19622 160
```
 
## Cleaning Data 
### Count NA's in each column and clean-up
```{r removeNAs}
unique(colSums(!is.na(training))) # NA's are whole column or 406 rows
nas = sapply(training, function(x) {sum(is.na(x))})
training <- training[, names(training) %in% names(nas[nas < 407])] # 19622 93
testing <- testing[, names(testing) %in% names(nas[nas < 407])] # 20 92
rm(nas)
```
 
### Remove near zero variance and descriptor variables 
```{r removeNZV}
# remove description and time cols
training <- training[,-c(1:7)]
testing <- testing[, -c(1:7)]
# remove near zero variance (NZV) variables
nzv <- nearZeroVar(training, saveMetrics=TRUE)
training <- training[, names(training) %in% rownames((nzv[nzv$nzv == 0, ]))]
testing <- testing[, names(testing) %in% rownames((nzv[nzv$nzv == 0, ]))]
rm(nzv)
```
 
### Split training data into train/validate with 60/40 split
```{r splitTrain}
set.seed(89)
inTrain <- createDataPartition(y=training$classe, p = 0.60, list=FALSE)
training <- training[inTrain, ]
validate <- training[-inTrain, ]
rm(inTrain)
```
 
 
## Classification Tree
Apply classification tree to dataset:
```{r tree, cache=TRUE}
mod.ct1 <- train(classe ~., method = 'rpart', data = training)
```
 
 
```{r dendogram}
mod.ct1
mod.ct1$finalModel
```
 
## Tree Dendogram
```{r} 
# plot dendogram with rattle package
library(rattle, quietly = TRUE)
fancyRpartPlot(mod.ct1$finalModel)
```
 
Overall the classification tree model predicts 0.51 accuracy for the training dataset, which is only marginally above guessing. Also, the classe D exercise is dropped completely from the final model.
 
## Random Forest with Caret Package 
 
### Training the model 
A Random Forest training model was applied to the data with the caret package. Out of bag (OOB) error estimate method was used for the bootstrap datasets.
```{r randomForest, cache=TRUE}
set.seed(89)
mod.rf5 <- train(classe ~., data = training,
                 method = 'rf',
                 trControl=trainControl(method='oob', seeds = c(89)),
                 proximity = TRUE)
mod.rf5
```
 
The accuracy of the final training model is 0.991 with mtry = 27. Giving an error rate of:
(1 - 0.991)*100 = 0.9%.
 
 
## Plot Model Convergence 
```{r rfConvergence}
plot(mod.rf5)
```
 
# Cross Validate with the remaining 40% of training data

For the training model to not have overfitted the dataset we would like to see an **out of sample error** that is better than the **in sample error** of 0.9%. 
 
```{r rfValidate}
pred.rf5 <- predict(mod.rf5, validate)
confusionMatrix(pred.rf5, validate$classe)
```
 
 
Accuracy of the cross validated model is 0.9992, giving an **out of sample error** of:
(1 - 0.9992)*100 = 0.08%.
  
 
## Variables of Importance 
The variables with the most influence on the final model fit are shown below.
```{r rfVarImp, fig.height = 9, fig.width = 6}
varImp(mod.rf5)
plot(varImp(mod.rf5))
```
 
 
## Conclusion 
The classification tree model accuracy was only marginally better than guessing at 0.51 and the final model dropped exercise classe D. Once trained the random forest model showed the greatest accuracy at predicting the exercise classe from the acceleromter data with an out of sample error of only 0.08%. The top 5 variables in predicting the exercise classes where 
        - **roll_belt**
        - **pitch_forearm**
        - **yaw_belt**
        - **pitch_belt**
        - **magnet_dumbbell_z**.
 
 
 
## Test Set Prediction 
The test set contains 20 observations. From the accuracy of the random forest validation model (0.9992) the odds of getting 20 tests all correct is:
 
p^20 = 0.9992^20 = 0.984121 or 98.4% chance.

```{r test}
pred.rf.test <- predict(mod.rf5, testing)
summary(pred.rf.test)
print(pred.rf.test)
```






